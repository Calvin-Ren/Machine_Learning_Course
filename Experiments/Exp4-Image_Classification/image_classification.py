# -*- coding: utf-8 -*-
"""Image_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15N54vR2SpjLdT0yAkPB-FN_1dpj8tYSU
"""

!pip install tensorflow-datasets

import tensorflow as tf
from keras.models import Sequential
import numpy as np
import pandas as pd
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
from keras import layers
import tensorflow_hub as hub
from sklearn.metrics import classification_report

(training_set, test_set), info = tfds.load(
    'tf_flowers',
    data_dir = './',
    split=['train[:80%]', 'train[80%:]'],
    with_info=True,
    as_supervised=True,
)
print("Training Set Size: %d" % training_set.cardinality().numpy())
print("Test Set Size: %d" % test_set.cardinality().numpy())

IMG_SIZE = 224
  
def format_image(image, label):
  
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
      
    # Normalisation
    image = image/255.0
    return image, label
  
batch_size = 32
training_set = training_set.shuffle(300).map(format_image).batch(batch_size).prefetch(1)
test_set = test_set.map(format_image).batch(batch_size).prefetch(1)

data_augmentation = Sequential(
  [
    layers.RandomFlip("horizontal", input_shape=(224, 224, 3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)

def getModel():
  model = Sequential()
  # pretrained_model= tf.keras.applications.xception.Xception(include_top=False,
  #                  input_shape=(224, 224, 3),
  #                  weights='imagenet')
  # for layer in pretrained_model.layers:
  #     layer.trainable=False
  model.add(data_augmentation)
  # model.add(layers.Dense(64, activation='relu'))
  model.add(layers.Flatten())
  model.add(layers.Dense(256, activation='relu'))
  model.add(layers.Dense(5, activation='softmax'))  
  model.summary()

  return model

model = getModel()
  
model.compile(optimizer='adam', 
              loss='sparse_categorical_crossentropy',
              metrics='accuracy')
  
epochs = 15
history = model.fit(training_set, epochs=epochs, 
          validation_data=test_set)

# 绘制训练 & 验证的准确率值
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# 绘制训练 & 验证的损失值
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

res = model.evaluate(test_set)
for (name, value) in zip(model.metrics_names, res):
    print(name, value) 

img, labl = next(iter(test_set))
print(classification_report(labl, np.argmax(model.predict(img), axis=1)))